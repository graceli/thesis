% Note that because I talk a lot about binding ... this discussion within my methods section may be quite important for examing members that understands the physics but do not understand how MD simulations in particular is rigoroous enough to make any of those predictions.  Having those details here means that I understand how that link is established and that I'm not just making up stories based on pretty pictures.  These are some of the goals that I want to acheive for the benefit of the reader of this chapter.


% From D. Caplan's thesis - Molecular mechanics (MM) is the empirical mathematical representation of atomic inter- actions in the classical limit. MM was developed over 50 years ago and has been applied to organic chemistry as a tool to estimate specific energetic properties of small molecules. Since then it has evolved into various functional forms (known as “force fields”) used to describe the potential energy of a system by computing atomic interactions. Force fields may vary in the way that they represent atomic particles to balance experimental accu- racy with computational efficiency. Molecular dynamics (MD) is a MM-based method in which force fields are used to calculate the position, velocity, and acceleration of atoms over time to produce a trajectory.

\chapter[Methods]{Molecular Modelling and Simulation}

\section{Molecular Mechanics}
% Start by describing quantum mechanics 
% Assumptions and limitations of molecular mechanics
In principle, the time-evolution of a molecular system can be predicted using quantum mechanics by solving the time-dependent Schr\"odinger's equation, which provides a complete description of the motion of atomic nuclei and electrons from first principles.\cite{Schrodinger:1926ka} Notably, this equation can only be solved analytically for a hydrogen atom, and must be solved numerically for more complex systems. Although many quantum-mechanics-based computational methods have been developed in recent years,\cite{Gogonea:2001us} they are still computationally prohibitive for probing the dynamics of most protein systems on a biologically-meaningful timescale because these systems, with solvent molecules included, typically possess on the order of 10$^{4}$ to 10$^{5}$ atoms.

Molecular mechanics is an approach in which a molecular system is treated using the principles of classical mechanics. In molecular mechanics, a molecule is modelled by a set of masses (atoms) connected by springs (bonds).  An empirical potential energy function (PEF) that only depends on the positions of the atoms is employed to describe the internal energy and interactions of molecules within a system.\cite{Cornell:1995td,Brooks:1983uc,Christen:2005fp,Jorgensen:1985wx} The theoretical basis for molecular mechanics is rooted in quantum mechanics via the Born-Oppenheimer approximation.\cite{Born:1927tb} Under this approximation, the electronic and nuclear motion of atoms are considered to be uncoupled, and therefore can be treated separately.
% Note that the previous sentence is a little vague -- what does it mean to be ``treated separately''
Because nuclei are much heavier than electrons, they are practically stationary on the time scales of electronic vibration. For this reason, the total energy (or stationary Hamiltonian, $H$) of a system can be considered to depend only on the electronic motion. As a consequence, the nuclear motion of a system is then governed by a potential energy function under the influence of a single electronic state. % Note: Regis said it was unclear.

% Although molecular mechanics is a very simplified model of molecular system, that made modelling of much larger biomolecular systems possible. 

The PEF employed in molecular mechanics corresponds to the potential energy surface of the molecular system in its electronic ground state.  % can't find a ref for this and all the places where I see this reference, I don't see a corresponding reference. 
In molecular mechanics, atomic nuclei are treated as point charges, and their electronic distribution is implicitly accounted for in the PEF.  Because electronics are not treated, no chemical reactions (i.e., bond formation) can occur.
% \cite{M. Born and R. Oppenheimer, Quantum Theory of Molecules, Ann. Physics, vol. 84, pp. 457â484, 1927.} -- can't find this article.
% \textbf{Say something good about MM approach}

\section{Force Fields for Biomolecules}

The functional form of the PEF together with its associated parameters define a \emph{force field}.  A typical empirical force field has many parameters to be determined.  These parameters are determined by fitting to quantum mechanical calculations, and to physical measurements (e.g., using data from X-ray crystallography, neutron diffraction, vibrational raman spectroscopy) of small organic compounds, building blocks of peptides and nucleic acids. Over time, force field parameters are adjusted to improve the agreement of predicted quantities. In the past four decades, a variety of force fields have been developed and applied toward the modelling of biomolecular systems involving proteins, nucleic acids and carbohydrates. The widely adopted force fields include AMBER,\cite{Cornell:1995td} CHARMM,\cite{Brooks:1983uc} GROMOS,\cite{Christen:2005fp} and OPLS.\cite{Jorgensen:1985wx,Jorgensen:1996vx,Kony:2002ji} Reviews and comparisons of these force fields are provided elsewhere.\cite{Beauchamp:2012eq,MackerellJr:2004p5558,Ponder:2003uw}  Although force fields may adopt different parameterization strategies, they share a similar general form of the PEF:
\begin{equation}
\label{eq:ff_general}
	V = V(bonds) + V(angles) + V(dihedrals) + V(impropers) + V(non-bonded).
\end{equation}

\begin{figure}
 \centering
 \includegraphics[width=5in]{figures/methods/mm_schematic.pdf}
 \caption[Schematic diagram illustrating the energetic terms of the potential energy function.]{Schematic diagram illustrating the energetic terms of the potential energy function.}
 \label{fig:mm_schematic}
\end{figure}

\subsection{Bonded Interactions}
The first four functional terms of Equation~\ref{eq:ff_general}, $V(bonds)$, $V(angles)$,  $V(dihedral)$, and $V(improper)$, define the through-bond interactions, covalent bond stretching, angle-bending, bond torsion angles, and planar dihedral angles terms, respectively. Covalent bond stretching can be described using Hooke's Law for harmonic motion,
\begin{equation}
\label{eq:bonds}
	V(bonds) = \sum_{bonds} k_b(b - b_0)^2.
\end{equation}

Likewise, angle-bending motions can also be described harmonically as
\begin{equation}
\label{eq:angles}
	V(angles) = \sum_{angles} k_{\theta}(\theta - \theta_{0})^2. \\
\end{equation}

In Equations~\ref{eq:bonds} and \ref{eq:angles}, $b$ and $\theta$ are variables representing the bond length and bond angle. The constants $k_{b}$ and $k_{\theta}$ are the equilibrium force constants for bonds and angles, respectively, and the constants $b_{0}$ and $\theta_{0}$ are the reference bond length and angle, respectively. The total energetic contribution from bond stretching and angle bending are computed by summing over all bonds and angles in the system. In addition, the torsion (or dihedral) angle of bonds is also important for describing molecular conformations.  These energetic terms are commonly accounted for by using a periodic function of the form,
\begin{equation}
\label{eq:torsion}
	V(dihedrals) = \sum_{dihedrals} \sum_{n} k_{\chi}(1 + cos(n\chi - \delta)),
\end{equation}
where $\chi$ is the dihedral angle, $k_{\chi}$ and $n$ are the height and the periodicity of the rotational barrier, respectively.  $\delta$ is the reference angle (or phase).  The value of $n$ is usually between 1 and 4, and depends on the specific force field parameterization procedure. Functions of this form are also included the PEF to ensure the planarity of planar chemical groups, in which case $\chi$ corresponds to a so-called improper dihedral angle.


\subsection{Non-bonded Interactions}
Non-bonded interaction potentials predominantly account for van der Waals and electrostatic interactions.  Accurate modeling of these interactions is particularly important for the transferability of a force field, which is the assumption that a force field developed based on a small set of molecules can predict properties of a broader set of molecules composed of similar chemical groups. The non-bonded forces are only applied to atom pairs from different molecules or separated by at least three bonds, and are pair-wise additive, that is, the total contribution to the potential energy from the non-bonded forces is the sum total over all interacting atomic pairs in a system. Van der Waals interactions are represented by the Lennard-Jones potential,

\begin{equation}
  \label{eq:lj_function}
  U_{LJ}(r) = (\frac{r_{min}}{r})^{12} - 2(\frac{r_{min}}{r})^6.
\end{equation}

The first term of Equation~\ref{eq:lj_function} represents a repulsive force at distances where atomic shells overlap. The second term represents the attractive force between atoms which is most favorable at a distance of $r_{min}$, the preferred interaction distance for a pair of atoms. $U_{LJ}$ is dependent on the distance between a pair of atoms, $r$, and decays rapidly to 0 as $r$ increases.

The modeling of electrostatics is paramount for describing interactions of polar and charged groups in biomolecules. To do so, the Coulombic potential,
\begin{equation}
  \label{eq:electrostatic}
  U_{coulombic}(r) = \frac{q_iq_j}{\epsilon r},
\end{equation}
is calculated for all atom pairs that carry partial charges or full charges at their nuclear centers.  In Equation~\ref{eq:electrostatic}, $q_{i}$ and $q_{j}$ are the point charges assigned to atoms $i$ and $j$, respectively, and $\epsilon$ is the dielectric constant.  In contrast to van der Waals interactions, electrostatic interactions can be significant for charged pairs that are separated by relatively long distances. Accordingly, in comparison to the Lennard-Jones potential, the Coulombic potential decays to zero at a much slower rate.
%\begin{figure}
% \centering
% \includegraphics[width=5in]{figures/methods/LJ_Coulumb_potentials.pdf}
% \caption[Lennard-Jones and Coulombic Potentials]{Lennard-Jones and Coulombic Potentials.}
% \label{fig:nonbonded_potentials}
%\end{figure}

As described in Chapter 1, hydrogen bonding is an important type of electrostatic interaction in biomolecular systems.  For this reason, a proper representation of hydrogen bonds should be captured by a force field. Some early versions of force fields have employed an explicit term solely for describing hydrogen bonding.\cite{MackerellJr:2004p5558} For example, the original AMBER force field introduced in 1984 added a function of the form $\sum_{hbonds} C_{ij}/R_{ij}^{12} - D_{ij}/R_{ij}^{10}$ to account for hydrogen bonds.\cite{Weiner:1984uw}  However, it was later demonstrated that hydrogen bonding interactions are most accurately accounted for by appropriate parametrization of van der Waals and electrostatic potential terms.\cite{Cornell:1995td,MackerellJr:2004p5558} Hence, most modern force fields for protein simulations, including the latest AMBER force fields, no longer utilize an explicit hydrogen bonding term.\cite{MackerellJr:2004p5558}
% Other things that I will not be discussing -- what were they again?

\subsection{Electronic Polarizability}
Electronic polarizability is the measure of the change in a molecule's electron distribution in response to an applied electric field, and is a property of matter which can be induced by electrostatic interactions with solvents or ionic reagents.  As mentioned above, most current empirical force fields use a fixed-charge model, that is, each atom in the system is assigned a single value that remains unchanged.  Polarizable force fields, which account for variations in charge distribution with atomic motion dielectric environment, have been introduced.\cite{Halgren:2001waa,Warshel:2007p5320} However, because of the associated high computational cost of using these force fields, they are not routinely used for biomolecular simulations.
% The introduction of polarizable force fields into common use has been inhibited by the high computational cost associated with solving this problem self-consistently.

\subsection{The AMBER and OPLS Force Fields}
In this section, I briefly describe two widely used force fields for protein simulations, AMBER and OPLS.  OPLS-AA/L\cite{Kaminski:2001eq} was employed in the studies presented in Chapters 3 to 5, and AMBER99\cite{Wang:2000uu} was employed in the study in Chapter 6.  More extensive and detailed reviews of empirical force fields for biomolecular simulations have been provided elsewhere.\cite{Ponder:2003uw,MackerellJr:2004p5558}

The AMBER force field and the associated molecular mechanics simulation package for the simulation of biomolecules were developed by the Kollman group.\cite{Weiner:1984uw}  The central ideas for parameterization were to fit atomic point charges to the quantum electrostatic potential (ESP) using \emph{ab initio} quantum mechanical calculations, and develop parameters for the bonded and van der Waals potential terms using experimental structural data and liquid-state simulations.\cite{Weiner:1984uw,Cornell:1995td} The initial parameters were improved upon via the reproduction of experimental measurements for model compounds. The early versions of the 1983 AMBER force field accounted for only non-aliphatic hydrogen atoms,\cite{Weiner:1984uw}  and an all-atom version of AMBER was later introduced in 1995.\cite{Cornell:1995td} Since then, many iterations of improvements upon the original all-atom AMBER force field have been developed.\cite{Garcia:2002gu,Sorin:2005iz,Hornak:2006gx,Duan:2003ws}
% Note that I lifted the above references from Zhuyi's thesis methods draft and I didn't check if they were appropriate.
In particular, AMBER99 (or ff99) is one such revision with the peptide group dihedral angles re-parameterized to improve the reproduction of peptide secondary structure.\cite{Wang:2000uu}

%The potential energy function for AMBER is as follows: 
%\begin{equation}
%\begin{split}
%V = \sum_{bonds} k_b(b-b_0)^2 
%   + \sum_{angles} k_{\theta}(\theta - \theta_{0})^2 \\
%   + \sum_{dihedrals} k_{\chi}(1 + cos(n\chi - \delta)) 
%   + \sum_{impropers} k_{\gamma}(\phi - \phi_{0})^2 \\
%   + \sum_{nonbonded} \frac{q_1q_2}{er} \\
%   + \sum_{nonbonded} \epsilon [(\frac{r_{min}}{r})^{12} - 2(\frac{r_{min}}{r})^6]
%\end{split}
%\end{equation}

The OPLS (Optimized Potentials for Liquid Simulations) force field, as its name suggests, was originally developed to reproduce the liquid-state properties (e.g., densities and heats of vaporization) of compounds. Parameters were first developed for water, ions, hydrocarbons,\cite{Jorgensen:1984vy} and were later extended to amides,\cite{Jorgensen:1985wx} peptides,\cite{Jorgensen:1985wx} and carbohydrates.\cite{Damm:1997tla}  As in AMBER, in early OPLS development, a partial united-atom model was used whereby nonbonded interaction sites were placed only on non-hydrogen atoms and polar hydrogens.\cite{Jorgensen:1988vg,Jorgensen:1985wx,Jorgensen:1984vy} All-atom versions of the OPLS force field (OPLS-AA) for organic molecules and peptide simulations were subsequently developed.\cite{Jorgensen:1996vx,Kaminski:2001eq} In OPLS, the parameters for non-bonded interactions were derived by comparisons to liquid-state thermodynamics, and the atom types and parameters for bonded interactions (bonds, angles, and dihedrals) were largely adopted from the AMBER all-atom force field.\cite{Jorgensen:1996vx}


\section{Molecular Dynamics Simulation}
% Approximations made in MD.
% Note the audience of your thesis.  It is good to cover basic ground.  I think I should also brief talk about enhanced techniques.
MD is an algorithm that simulates the motion of a system under the influence of a specific force field by following molecular configurations in time according to Newton's equation of motion. 

% This is the part with the time propagation using the Equations of motion
In a system composed of $N$ interacting particles, the force acting on each particle is determined by taking the spatial derivative of the potential energy of the system, $V(r_{1}, r_{2}, ... , r_{N})$.  In MD simulations, this potential energy is approximated by a molecular mechanics force field as described above.  The force on each particle $i$, at time $t$, is given by
% Not exactly ... according to Chris Madill's thesis, U is the potential energy between an atom pair?  Clear up the core algorithm!
\begin{equation}
% F_i = - \nabla U
 \vec{ F_i} = - \frac{\partial V}{\partial \vec{r_i}}, i = 1, 2, 3, ... , N.
\end{equation}

The variable $r_{i}$ represents the spatial coordinates of the particle $i$. The calculated force vectors are summed together to yield the net force vector for each atom in the system. By Newton's second law of motion, the acceleration, $a_i$, of each atom is given by 
\begin{equation}
\label{eq:fma}
\vec{a_i}(t) = \frac{\vec{F_i}}{m_i},
\end{equation}
where $m_i$ is the mass of the $i$th particle. 
Hence, the velocity at a subsequent time step, $\vec{v_{i}}(t + \delta t)$, is then given by,
\begin{equation}
\label{eq:velocity}
\vec{v_i}(t+\delta t) = \vec{v_i}(t) + \int_{t}^{t+\delta t} \vec{a_{i}}(t) dt = \vec{v_i}(t) + \vec{a_{i}}\cdot \delta t.
\end{equation}
The position of atom $i$ at time $ t + \delta t$ is then,
\begin{equation}
\label{eq:displacement}
\vec{x_i}(t + \delta t) = \vec{x_i}(t) + \vec{v_i}(t)\delta t + \frac{\vec{a_i}(t)\delta t^2}{2}.
\end{equation}
As shown in Equations~\ref{eq:velocity} and \ref{eq:displacement}, the predicted positions of each of the $N$ particles are approximated numerically by finite difference in MD simulations using a time-integration algorithm. For example, the leap-frog and velocity-verlet algorithms are commonly used in MD simulations.\cite{Hockney:1974tu,Swope:1982tq} To ensure numerical stability, a small integration time step $\delta$t in the range of 1 - 4 femtoseconds (fs) is chosen. In MD simulations of biomolecular systems, when the bond lengths involving hydrogens are frozen, a 2 fs timestep is commonly chosen because it is twice the time period for the fastest vibrational motion (existing in bonds involving hydrogen). Once the position of each particle is computed, subsequent interatomic forces are updated based on these new coordinates, and the entire process is repeated to obtain the coordinates of the system at future time steps. 

% [Ref: Chris Madill's and Tom's thesis]

% There are many different forms of integration algorithms, with the most common being the Verlet and leap-frog algorithms. 
% According to gromacs manual:
% md - is a leap-frog algorithm for integrating Newton's equation.
% Note that in absence of pressure and temperature coupling, verlet and leap-frog is equivalent ... and generates identical trajectories of motion.

% How much detail? Talk about the velocity verlet integration algorithm ? -- I'm going to study up on this but will eliminate this from my thesis ...


% Marty's thesis included a little bit on the verlet algorithm.  CN did not.

\subsection{Temperature and Pressure}
% My goal is to describe how temperature and pressure coupling is handled in MD at a high-level without going into the details of the math.
% Ref: Understanding Molecular Simulations by Frenkel Daan.
Temperature is a measure of the kinetic energy of the system, and the instantaneous temperature of a macroscopic system can be determined from the kinetic energy of every atom.  The theorem of equipartition of energy states that in a (classical) many-body system at thermal equilibrium, the average kinetic energy (K) per degree of freedom is related to the thermodynamic temperature, $T$, via
\begin{equation}
  K =  \frac{1}{N} \sum_{i=1}^{N} \frac{1}{2} m_{i}v_{i}^{2} = \frac{3}{2} k_BT,
\end{equation}
where $m_{i}$ is the mass of the atom $i$, $v_{i}$ is the velocity of $i$ along a single dimension, and $k_{B}$ is the Boltzmann constant. In MD simulations, the temperature of the system is the total kinetic energy of the system normalized by the number of degrees of freedom in the system, that is,
\begin{equation}
  T(t) = \frac{1}{3N} \sum_{i=1}^{N} \frac{m_iv_i^2(t)}{k_B},
\end{equation}
where $N$ is the number of atoms and $v_{i}(t)$ is the velocity of atom $i$. To simulate a system close to laboratory conditions,  a thermostat and a barostat are employed to control both the temperature and pressure of a simulation system, respectively.  Many algorithms exist for the implementation of thermostats and barostats, and are available in modern molecular dynamics simulation software packages.\cite{Brooks:2009ew,Hess:2008p5353}   In this thesis, the Berendsen\cite{Berendsen:1984p9257} and Nos\'e-Hoover algorithms,\cite{Nose:1984em,Hoover:1985wf} and the Parrinello-Rahman\cite{Nose:1983vt,Parrinello:1981vy} algorithm were employed for temperature- and pressure-coupling, respectively.


% These algorithms have been validated to produce the correct statistical mechanical ensemble averages.  
%\cite{[25] Nose Ì, S. A molecular dynamics method for simulations in the canonical ensemble. Mol. Phys. 52:255â€“268, 1984.[26] Hoover, W. G. Canonical dynamics: equilibrium phase-space distributions. Phys. Rev. A 31:1695â€“1697, 1985.}

%Below is from the GROMACS manual:
% While direct use of molecular dynamics gives rise to the NVE (constant number, constant volume, constant energy ensemble), most quantities that we wish to calculate are actually from a constant temperature (NVT) ensemble. 
% Using the same idea, we can couple the system to a pressure bath.  This method is called the Parrinello-Rahman pressure coupling, and the theory has been shown to correctly produce the NpT ensemble.
% \cite{Parrinello, M., Rahman, A. Polymorphic transitions in single crystals: A new molecular dynamics method. J. Appl. Phys. 52:7182â€“7190, 1981. [35] Nose Ì, S., Klein, M. L. Constant pressure molecular dynamics for molecular systems. Mol. Phys. 50:1055â€“1076, 1983.}
% Should I include the equations? I haven't seen this in other thesis, perhaps its too much detail. -- Yes this is too much detail.

%\subsection{Solvent Representation}
%% Talk about how solvent is accounted for
%The most realistic simulations treat the solvent environment by explicitly including the water molecules.  \textbf{How solvents are parameterized.  Can mention a few details about TIP3P water model. I actually don't know much about TIP3P} Solvent models are chosen to be consistent with the force field used for modelling the protein.  Although using explicit solvent leads to the most realistic simulations, these simulations are computationally expensive.  In some cases, instead of using explicit solvent molecules, implicit solvation can be used, that is the presence of solvent is approximated by using a potential. However, the implicit solvation suffers from several key weaknesses including a poor description of water-mediated interactions, directionality of water hydrogen bonds and only an approximate treatment of the nonpolar contribution to solvation.
%Hence,  is much less accurate and can introduce force field inconsistencies leading to inaccurate results.\cite{Yang:2013ff}

\subsection{Periodic boundary conditions}
Periodic boundary conditions (PBC) are a technique by which the central simulation cell (or ``box'') is replicated along each of its dimensions to form a system with an infinite number of images. It is used to alleviate artificial phase boundaries imposed by a finite simulation cell.  Furthermore, PBC allow the simulation system to be treated as a bulk system, akin to \textit{in vitro} experimental conditions.  To avoid counting duplicate interactions from multiple adjacent cells, a minimum image convention is applied -- an atom $i$ interacts with another atom $j$ only in its closest periodic image.

\subsection{Connection to Statistical Mechanics}
MD simulations yield information about the microscopic states of a macroscopic system characterized by thermodynamic variables such as the temperature, pressure, and number of particles.  Statistical mechanics is a body of theory that provides a rigorous connection between the microscopic arrangements of a system (determined by MD simulations) to its thermodynamic properties.

MD simulations can be carried out in the canonical (NVT) ensemble, where the number of particles (N), volume (V) and temperature (T) are held constant, or, alternatively, in the isothermal-isobaric (NPT) ensemble, where number of particles and temperature are held constant, but the average pressure, instead of the volume, is held constant by allowing the volume of the simulation box to fluctuate. Because the NPT ensemble is the closest to typical experimental conditions, simulations are often carried out in this ensemble.

For a canonical ensemble of microstates, the probability of finding a system in the microstate $i$, with an energy $E_{i}$ is given by the Boltzmann distribution,
\begin{equation}
\label{eq:boltzmann}
p_{i} = \frac{1}{Z}e ^{\frac{-E_{i}}{kT}}.
% Z = e ^{\frac{-A}{k_{B}T}}
\end{equation}
$Z = \sum_{i} e ^{\frac{-E_{i}}{kT}}$ is the normalization factor (or the \emph{partition function} of a system) such that $\sum_{i} p_{i} = 1$.
Any thermodynamic variable can then be derived from the partition function. For example, free energy, an important thermodynamic quantity, measures the useful work obtainable from a system under a certain set of conditions.  It is called the Gibbs free energy (G) for a system in the NPT ensemble, and the Helmholtz free energy (A) for a system in the NVT ensemble. In biochemistry, a central quantity of interest is the change in free energy between two states of interest, which measures whether a reversible biochemical process will occur spontaneously.  The relative free energy $\Delta$G of any two states, 0 and 1, is related to their respective probabilities $p_{0}$ and $p_{1}$ via
\begin{equation}
\Delta G = - k_{B}Tln \frac{p_{0}}{p_{1}}.
\end{equation}

Performing a MD simulation yields a time-trajectory of the positions of atoms in the system from which we can obtain time-averaged thermodynamic properties of the system.  However, in an experiment, the macromolecular observables measured are a result of an average over all possible microstates of a system, that is, an \emph{ensemble average}.  This apparent conundrum is reconciled by one of the fundamental axioms of statistical mechanics, the ergodic hypothesis, which states that if a system is given long enough time to evolve, the time average of any of its macromolecular properties is equivalent to its ensemble average.\cite{mcquarrie2000statistical}  In practice, this means that if a simulation sufficiently samples the relevant regions of phase space (i.e., the collection of all possible configurations of a given system specified by its coordinates and momenta), then statistically-meaningful experimental properties can be extrapolated from such a simulation.

\subsection{Enhanced Sampling Techniques}
As described above, in an MD simulation, atomic motion at a given temperature is dictated by a potential energy function, and states are sampled with probabilities dictated by the Boltzmann distribution. Given an infinite amount of time, a simulation will sample all states of a system's potential energy landscape. However, infinitely long simulations are not possible to achieve computationally.  Thus, because of the rugged energy landscapes common to biomolecular systems, many important states may not be sampled on the timescales of a typical simulation.
Furthermore, it is even more challenging to adequately sample the complex conformational landscape of disordered proteins because of the large number of conformational states that may need to be sampled in order to fully characterize their structural ensemble.\cite{Rauscher:2010p5682}

Generalized-ensemble algorithms are a class of algorithms that can be used with molecular simulations to enhance conformational sampling.  Simulated tempering (ST) and replica exchange (RE) are two well-known such algorithms that can be used to enhance sampling by allowing simulations to diffuse in temperature-space, while obeying Boltzmann statistics at any of the temperatures visited (Equation~\ref{eq:boltzmann}).\cite{Marinari:1992p5428,Mitsutake:2001p5380} These algorithms rely on the fact that at higher temperatures the free energy landscape of a biomolecular system becomes less rugged, and, hence, the crossing of energetic barriers is facilitated.  Simulations are carried out at different temperatures using a temperature range that encompasses the temperature of interest (typically, room temperature). The optimal temperature range depends on the size and composition of the system.\cite{Rauscher:2009wr,Rauscher:2010p5682} Although generalized-ensemble methods, when combined with MD simulations, can significantly enhance conformational sampling of biomolecular systems,\cite{Zuckerman:2006tk,Rauscher:2009wr} they are computationally expensive, and often require a parallel supercomputing platform to carry out a single study in a feasible time frame.\cite{Rauscher:2010ja}

\subsubsection{Simulated Tempering (ST)}
The ST algorithm utilizes a generalized Hamiltonian that depends on all configurational degrees of freedom and temperature\cite{Marinari:1992p5428}:

\begin{equation}
H(X,m) = \beta_{m}H(X) - a_m,
\end{equation}

where $X$ is the configuration of the system, $\beta_m$ is the inverse temperature, $H(X)$ is the system's original Hamiltonian, and $a_{m}$ is a constant which depends on temperature.  Hence, the probability of sampling a given temperature, $T_m$ is 

\begin{equation}
P(T_m) = e^{a_m(T)}e^{-\beta_m H(X)}.
\end{equation}

The weight factors, $a_m(T)$, are dimensionless Helmholtz free energies as follows 
$a_m(T) = \beta_m A_m$,

where $A_m$ is the free energy of the system at temperature $T_m$.  $a_m(T)$ must be chosen such that an uniform probability distribution in temperature space is achieved. Allowing a uniform sampling of temperature in turn induces a random walk in PE space which allows a system to escape from local minima.   

In a typical ST simulation, a short canonical MD simulation is performed at temperature $T_i$ followed by an exchange attempt to a neighbouring temperature, $T_j$. An exchange attempt has the probability 

\begin{equation}
% exchange equation
p(T_i \longrightarrow T_j) = min
\begin{cases} 
1 &  \\ 
e^{-(\beta_j - \beta_i)E + (a_j - a_i)}. &  
\end{cases}
\end{equation}

The weight factors ($a_m$) are  \textit{a priori} unknown and must be determined by a iterative procedure.  A main disadvantage of ST is that determining an accurate set of weight factors for complex biomolecular systems can be very challenging to obtain.\cite{Rauscher:2009wr}

% This disadvantage lead to the development of a class of methods called replica exchange.

\subsubsection{Replica Exchange (RE)}
Replica exchange (RE) bypasses the problem of determining unknown weight factors while still allowing random walks in temperature space.\cite{Hansmann:1997p5405,Mitsutake:2001p5380} RE molecular dynamics simulation is briefly review below. Detailed description and derivation for the algorithm can be found elsewhere.\cite{Mitsutake:2001p5380}

In RE, a system of multiple non-interacting copies or replicas of a system where each replica has a different temperature are considered. 

Let $X=\{x_i^{T_i}\}_{i=1}^{M}$, where $x_i^{T_i}$ is a replica at temperature $T_i$, with coordinates $q_i$ and momenta $p_i$.  Recall that the Boltzmann weight factor of $x$ in the generalized ensemble is $W(x;T)=e^{-\beta H(q)}$.  Because the replicas are assumed to be independent, the weight factor for $X$ is 
%%% RE weight factor for X |X| = M
\begin{equation} \label{RE_weight}
W_{REM}(X) = \Pi_{i=1}^{M} e^{-\beta_{T_i} H(q_i^{T_i})}
\end{equation}
Periodically, a pair of replicas $i$ and $j$ in $X$ exchange their temperatures, 
%%% exchange X->X'
\begin{equation}
X=(\ldots,x_{T_i}^i,\ldots,x_{T_j}^j,\ldots) \longrightarrow X'=(\ldots,x_{T_j}^i, \ldots,x_{T_i}^j,\ldots)
\end{equation}

%Under the MC framework, momenta is not present in the system. However, to have RE work with MD, momenta of the two replicas must be scaled accordingly after the temperature exchange as follows in order to preserve the correct average kinetic energy,
%%% X-> X' in detail
%\begin{eqnarray}
%	x_{T_i}^i &=& (q^i,p^i)_{T_i} \longrightarrow x_{T_j}^i = (q^i,p^{i'})_{T_j}\\
%	x_{T_j}^j &=& (q^j,p^j)_{T_j} \longrightarrow x_{T_i}^j = (q^j,p^{j'})_{T_i}
%\end{eqnarray}
%Where the new momenta $p^{i'}$, $p^{j'}$ are rescaled as 
%%%% scaling of momenta for MD
%\begin{eqnarray}
%	p^{i'} &=& \sqrt{\dfrac{T_{new}}{T_{old}}} = \sqrt{\dfrac{T_j}{T_i}}p^i\\
%	p^{j'} &=& \sqrt{\dfrac{T_{new}}{T_{old}}} = \sqrt{\dfrac{T_i}{T_j}}p^j
%\end{eqnarray}

% detailed balance
In order to have the $M$-replica system under a set of exchanges to converge to the equilibrium (Boltzmann) distribution, the detailed balance condition should hold. That is,
\begin{equation}
W_{REM}(X)w(X\rightarrow X') = W_{REM}(X')w(X'\rightarrow X),
\end{equation}
where $w(X\rightarrow X')$ is the transition probability to go from state $X$ to state $X'$.  This directly leads to, 
\begin{equation}
\frac{w(X\rightarrow X')}{w(X'\rightarrow X)} = \frac{W_{REM}(X')}{W_{REM}(X)} = e^{-(\beta_{T_j}-\beta_{T_i})(E(q^i)-E(q^j))}
\end{equation}
% => the acceptance criterion
Let $\Delta = (\beta_{T_j}-\beta_{T_i})(E(q^i)-E(q^j))$, then the Metropolis acceptance criterion which allows the exchanges to take place is given by, 
\begin{equation}
	w(X\rightarrow X') = w(x_{T_i}^i | x_{T_j}^j) = min\{1, e^{-\Delta}\}.
\end{equation}

In summary, a replica exchange MD simulation is implemented as follows: \\
Without loss of generality, assume that $T_1 > T_2 > \ldots > T_M$ so that $\beta_1 < \beta_2 <  \ldots < \beta_M$, then
\begin{enumerate}
\item Simulate each replica $i$ at fixed $T_i$ in parallel and independently for some number of steps using MC or MD
\item A pair of replicas $i$, $j$ with neighboring temperatures $T_i$, $T_j$ are exchanged with probability $w(x_{T_i}^i | x_{T_j}^j)$
\end{enumerate}

% PROBLEM with RE: exchange schedule => need to increase replicas with DOF of system simulated
In the RE scheme, through exchange of replicas, states trapped at local minima are allowed to cross barriers by jumping to higher temperatures. Therefore, a random walk in the temperature space (and thus, PE space) is realized for each replica.

An advantage of RE over ST\cite{Marinari:1992p5428} is that there is no need for weight factor determination.\cite{Mitsutake:2001p5380} Furthermore, RE is suited for implementation on a parallel computing system. Each replica can be assigned to run on a node since the amount of information exchanged between replica (nodes) is minimal. It should be noted here that, unlike conventional MD,  dynamic information is lost upon using generalized ensemble sampling methods due to unphysical transitions and exchanges that occur in each simulation.

% In recent years RE have gained immense popularity as the algorithm to use for protein folding studies, especially due to the exponential increases in computing power. However, RE is not devoid of problems.  It was shown that the number of replicas required is $O(\sqrt{f})$, where $f$ is the number of degrees of freedom (DOF) of a system.\cite{fukun} For large, complex systems with many DOFs such as proteins solvated in explicit solvent, sampling using RE can become computationally prohibitive even if running on powerful, homogeneous parallel computing clusters. 

% \textbf{Replica exchange has been the most widely used of the methods we discuss in this chapter to enhance sampling of biomolecular simulations.  ST-based algorithms have the advantage over RE-based algorithm in that ... STDR is a ST-based algorithm which ....}

\subsubsection{Simulated Tempering Distributed Replica (STDR)}
STDR is a generalized-ensemble simulation method based on ST.  We briefly review the methodology below. An in-depth derivation of the algorithm is out of the scope this thesis and is provided elsewhere.\cite{Rodinger:2006dl,Rauscher:2009wr}

In STDR, individual replicas are coupled through a generalized Hamiltonian containing a potential energy term, the distributed replica potential energy (DRPE), which depends on the distribution of all replicas in the following form:

\begin{equation}
DRPE = c_1 \sum_{m=1}^{M}\sum_{n=1}^{M} [\lambda_{m,linear} - \lambda_{n,linear} - \omega (m-n)^2] + c_2 [ \sum_{n=1}^{M} 
\lambda_{m,linear} - \omega \sum_{n=1}^{M} m ] ^ 2
\end{equation}

The DRPE enforces a desired sampling distribution of the reaction coordinate. $M$ is the total number of replicas. $m$ and $n$ are the indices representing replicas. The values denoted by $\lambda$ represent a linearly-spaced temperature coordinate. The constant $\omega$ is the ratio of the number of temperatures to the number of replicas.  $c_1$ and $c_2$ are constants and are used to modulate the influence of the DRPE, which enforces the homogeneous temperature sampling of replicas.

The probability of accepting a move from a temperature $T_i$ to a neighbouring temperature $T_j$ is
 
 \begin{equation}
% exchange equation
p(T_i \longrightarrow T_j) = min
\begin{cases} 
1 &  \\ 
e^{-(\beta_j - \beta_i)E + (a_j - a_i) - (DRPE_j - DRPE_i) } &  
\end{cases}
\end{equation}

If the weight factors are inaccurate, ST results in uneven sampling of the temperature coordinate. However, a key advantage of STDR over ST is that the introduction of the DRPE recovers homogenous sampling and greatly reduces the requirement for accuracy in the dimensionless Helmholtz free energies.\cite{Rauscher:2009wr}  Furthermore, due to limitations in the implementations of RE, STDR has been demonstrated to be more computationally-efficient than REMD for sampling the conformational landscape of shorter peptides such as octapeptides.\cite{Rauscher:2009wr}

In Chapters 3 and 4 of this thesis, ST and STDR algorithms were utilized, respectively, to generate the structural ensembles of monomeric (GA)$_{4}$ and A$\beta$(16-22) peptides.

%\subsubsection{Approaches for Determining Protein Conformational Ensembles}
%It was mentioned in Chapter 1 that enhanced sampling may be used to speed up simulations.  Here we provide a high level overview of the approaches that were developed that have been useful in sampling of peptide and protein conformations in molecular simulations. 
%
%The use of temperature to overcome energetic barriers in the system. Here I can talk about what enhanced sampling is, and how they can be applied to understanding the properties of disordered peptides. Cite Sarah.  
%I should read both Sarah's and Chris's thesis chapters relating to sampling.  Chris's is all about sampling. Since I refer extensively to enhanced sampling, I should make a mention of it.
%
%\subsubsection{Approaches for Calculating Protein-Ligand Binding Affinities}
%Note: This section could actually be put in the introduction.  As this may not require understanding the details of simulations.  Leave this hear for now and can move it as a section to the introduction ... maybe after Regis has seen both chapters together.
%
%I can show the thermodynamic cycle for getting Delta G, like the one that I had in my transfer proposal.  Describe why this can be used to determine free energies.  And then mention the techniques that were invented in the past to do so. These approaches are not applicable to the problem of this thesis, but this background is provided to give the reader perspective. Point to another review article and say this is discussed in detail. I can discuss how to determine enthalpic and entropic contributions.


%\subsection{Better Hardware}
% Here can describe how better hardware - bigger and better machines have led to improvements and advancements in this field.

% Initial conditions -- initial positions of the atoms in the system

\section{Preparing a Biomolecular System for MD Simulation}

Coordinates for the initial input into a simulation need to be prepared carefully and appropriately before the MD simulation is performed.  In this section, I provide an overview of this process. First, the structure of the protein of interest needs to be generated. If the structure of the protein of interest is known (either from crystallography or NMR), then its spatial coordinates can be extracted from the Protein Databank (PDB).  At this point, missing structural information, such as missing residues (usually those participating in highly-dynamic loops), are modelled into the protein. Furthermore, because a crystal structure does not contain information about hydrogen atoms, they need to be added to the model; the protonation state of basic and acidic residues in the protein needs to be assigned. This can be done by predicting the pKa for each residue or by visually examining the structure for the presence of hydrogen bonds.  

After the protein structure is prepared, the simulation environment is prepared to closely mimic \emph{in vitro} experimental conditions: the protein is solvated and other compounds of interest such as ligands, cosolutes, and salt are added to the simulation box. For more complex simulation systems, such as those of membrane proteins which require the presence of a lipid bilayer, additional steps need to be taken before the system is ready for simulating.\cite{Anezo:2003ft,Kandt:2007p405}
% Also make sure that at this point everyone in my committee understands that there is no ionization in the simulations and no chemical reactions.

\begin{figure}
 \centering
 \includegraphics[width=4.5in]{figures/methods/simulation_box.pdf}
 \caption[An example snapshot of a MD simulation system.]{An example snapshot of a MD simulation system. The protein (yellow) is shown in a cartoon representation. Cosolute molecules (\emph{scyllo}-inositol) are rendered in a space-filling representation.  Water molecules are shown as blue lines.}
 \label{fig:simulation_box}
\end{figure}

Energy minimization is usually performed on the system to remove any bad contacts that could have been introduced during system preparation. An example of a starting state of a simulation is shown in Figure~\ref{fig:simulation_box}. Prior to performing production dynamics, the system is first equilibrated to remove any bias inherent in the initial configuration.  This equilibration step is usually a short simulation that is performed to allow the solvent molecules to relax around the protein and for the system reach thermal equilibrium.  During this period, the system's temperature, pressure, and volume are closely monitored to ensure that they converge to their intended values. The length of the equilibration simulation is highly dependent on the system of interest.  A straightforward method for delineating the equilibration period for a simulation of a protein with well-defined structure is to measure the time-evolution of the root-mean-square deviation (RMSD) of the protein with respect to its crystal structure. Typically, only the data beyond the time at which the RMSD is observed to plateau is included in the final data analysis. 

%\begin{figure}
% \centering
% \includegraphics[width=5in]{figures/methods/equilibration.pdf}
% \caption[RMSD from the initial crystal structure calculated from an equilibriation]{Equilibration of the simulation system.}
% \label{fig:simulation_equilibration}
%\end{figure}

\addcontentsline{toc}{section}{Bibliography}
\bibliographystyle{plain}
\bibliography{introduction}

%\section{Application of MD in structure-based drug discovery}
%
%% \1 (Why computational?) Can help us get protein dynamics is important for understanding protein function. We want to understand protein function because we want to be able to design drugs to cure diseases.
%
%% \1 A important application of MD simulation in biochemistry is the predicting of protein-ligand binding free energies.
%
%One application of MD simulations is in rational drug design. In recent years structure-based computer modeling of protein-ligand interactions have become a core component of modern drug discovery.  In early stage drug discovery, a target is identified along with putative binding sites.  Then, the structure of the target is determined using structural determination techniques such as NMR or X-ray crystallography.
%% [See Tom's thesis]
%Ligands which may act as potential drugs are expected to bind with a high affinity (low $K_d$) to the binding site. The goal is to discover,  high specificity inhibitors of a protein (usually an enzyme). In this process, the binding free energy of the ligand to its target is used to quantitatively evaluate how well a ligand binds. A crude estimate of the binding affinity can be obtained using computational docking methods, where the energetics of binding is typically estimated without accounting for either ligand or protein flexibility.  Although docking is fast, it is often inaccurate for identifying true drug candidates.
%
%With computer hardware becoming faster and cheaper, MD simulations can be used to rapidly prototype experimental ideas -- for example, one can perform computational alchemy, that is, ``mutate'' residues to test various hypotheses. Furthermore, simulations may be used to determine whether a chemical change will produce a more potent drug candidate. Currently, state of the art computational binding studies use MD simulations, where the protein and drug is allowed to relax and freely move about in the system. However, in the case of understanding a specific binding reaction often needed when developing an enzyme inhibitor, the ability to observe the relevant binding events is a low probability event on the timescale achievable by simulations. Therefore, a few enhanced techniques have been developed to accelerate this process.  They are briefly introduced below.
%
%\section{Free energy calculations}
%There are two advanced methods that have been developed for determining the absolute binding free energies in combination with MD simulations.
%
%% \3 Linear interaction energy -- Out of scope
%% \3 MM/PBSA - no explicit account for solvents -- Out of scope
%\subsection{Thermodynamic perturbation}
%This is the paper that I am taking most of the topics here\cite{Gilson:2007hz}
%
%\subsection{Thermodynamic integration}
%I actually have no idea what this is, and would be hard pressed to explain this properly.
%In this case, I don't think I should be covering these topics in my thesis.
%
%\subsection{Free energy perturbation}
%Alchemically change one molecule into another
%
%\section{Review of MD studies of amyloid inhibition by small molecules}
%% MD studies using brute-force sampling. Aid in medicinal chemistry by making suggestions for how to design new AD drugs.
%
%\begin{outline}
%	%  Excerpt from Transfer proposal
%	\1 In recent years, molecular dynamics simulations have been intensively used to investigate the molecular basis of the structure and stability of amyloid fibrils. 
%	
%	\1 MD simulations of Congo red binding have been done with the protofibril-like crystal structure composed of the segment GNNQQNY.\{Wu, 2007 \#621\}
%	
%	\1 A recent simulation study of an N-methylated peptide with A$\beta$16-22 models of amyloid aggregates has provided insight into the possible mechanism of action of peptide inhibitors of amyloid formation.\{Soto, 2007 \#597\} This peptide inhibitor was shown to preferentially bind monomers to form dimers, possibly acting to inhibit fibril formation by sequestering monomers. However, peptide-based inhibitors have poor pharmacological profiles as they are actively broken down by proteases in the stomach and are difficult to transport across the blood-brain barrier. In addition, these peptide inhibitors specifically target A$\beta$ and thus do not have the potential to treat multiple amyloid diseases.
%\end{outline}


% Scrap
% Motivate the use of MD simulations
% Describe the details of molecular dynamics simulations
% Review the basic derivations of MD simulation equations and why they work

% Molecular dynamics simulations are a useful tool to study the structure, dynamics, and interaction of biomolecules. 

% MD is a numerical algorithm which solves a system of Newtonian equations of motion, and provides as output the time-trajectory of atoms with femtosecond time resolution.

% To review before my defense

% Details of the mathematics (need to review the basic theory + Taylor series expansion) - get a book - tomorrow maybe?

% Why is MD correct? Describe the fundamental assumptions of MD. Here, I want to give the readers who aren't familiar with the methodological details of MD a sense of the rigorousness of MD.

% The assumption at a hand-wave level adapted from Tom's thesis

% - Relationship between force and energy 
% - Relationship between momentum and velocity 
% - Why numerical approach must be used (no analytical solution for N > 2)
% - How is the force field plugged into the general algorithm.






% \subsection{Setting up a MD simulation: practical aspects} - Here are some details to run a MD simulation of a biomolecular system.  Should I omit this from my introduction? This is not really essential in understanding the rest of my thesis, or is it? Perhaps this should go into an appendix instead -- this isn't interesting. The following steps are often used to setup and start a MD simulation system of a protein. First, a pre-determined structure, typically a coordinate structure from X-ray crystallography or NMR, or homology-modelling data. Then a force field and solvent is chosen.


%\section{Limitations of MD simulations}
% Rauscher:2010p5682,Rauscher:2009wr}  % Ref: DE Shaw and CN
% Schlick T (2010) Molecular modeling and simulation: an inter- disciplinary guide, interdisciplinary applied mathematics, vol 21, 2nd edn. Springer, New York


% Given the approximations of MD, MD is well-suited for probing the dynamics of complex systems on the timescale of picoseconds to seconds. ???

%Roughly speaking, one would like to run a simulation at least 10 times longer than the slowest important timescale in a system. Unfortunately, many biomolecular timescales exceed 1 ms, and in some cases by orders of magnitude (44).\cite{Zuckerman:2011dz} For molecular simulations to reliably predict, guide, and help explain experiment, these simulations require force fields of sufficient accuracy, adequate sampling of the relevant biomolecular motions (convergence) and a correct representation of the experimental conditions. Failures in any of these areas yield results which disagree with experiment.Until sampling is adequate, equilibrium properties computed from a simulation remain biased by the systemÕs starting state and no meaningful comparison with experiment is possible [6]. 

%% copied from Zukerman\cite{Zuckerman:2011dz}
%\textbf{Although routine explicit-solvent MD simula- tions are now four or five orders of magnitude longer (i.e., 100-103 ns currently), modern MD studies still appear to fall significantly short of what is needed for statistically valid equi- librium simulation (36, 38). Roughly speak- ing, one would like to run a simulation at least 10 times longer than the slowest impor- tant timescale in a system. Unfortunately, many biomolecular timescales exceed 1 ms, and in some cases by orders of magnitude (44).}
%% Other references that are relevant for sampling \cite{Grossfield:2009bn}
%
%% Copied from \cite{Mobley:2011ks}
%\textbf{For molecular simulations to reliably predict, guide, and help explain experiment, these simulations require force fields of sufficient accuracy, adequate sampling of the rel- evant biomolecular motions (convergence) and a correct representation of the experimental conditions. Failures in any of these areas yield results which disagree with experiment. 
%
%We may be tempted to blame disagreement with experiment on just one of these areasÑforce fields are perhaps the most common scapegoat, sometimes with good reason [1Ð5]Ñbut any or all of the three may be a weak point. And, in some sense, adequate sampling is the weakest link. 
%
%Until sampling is adequate, equilibrium properties computed from a simulation remain biased by the systemÕs starting state and no meaningful comparison with experiment is possible [6]. 
%
%With an inadequate force field or a poor representation of the experimental conditions, results will disagree with experiment, but will be robust and improvement is relatively easy, but not so with inadequate sampling.}
%
%% copied from Sarah's thesis
%\textbf{Achieving complete (or even adequate) conformational sampling is one of the key challenges in biomolecular simulations.\cite{Gnanakaran:2003vh} The energy landscape of most biomolecules is ÒruggedÓ and the source of this ruggedness is two-fold. The energetic barriers separating accessible states are often larger than the available thermal energy, and there are typically a large number of states to be sampled. The timescales of many biomolecular processes, such as protein folding, are still far beyond the reach of our current computational capability, which is generally limited to the 10-8-10-7 s timescale for continuous simulations. For example, even the folding of small domains or secondary structure elements, such as ?-hairpins and mini-proteins, occur on the 1-10 ?s timescale.1 
%
%Consequently, conventional or Òbrute forceÓ molecular dynamics (MD) alone is often insufficient to achieve complete Boltzmann sampling of the important states of many biologically relevant systems. For this reason, generalized-ensemble algorithms have become popular tools for conformational sampling.}

% Topics that I'm not going to discuss
%Evaluating the convergence of simulations is still a challenge - I don't want to  go into this as this is out of the scope of my thesis.
%Limitations in the accuracy of current force fields - Don't talk about this .. but this will probably come up during the defense regardless.